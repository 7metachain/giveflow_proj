import { NextRequest } from 'next/server'
import { AI_CONFIG, type ChatMessage } from '@/lib/ai-client'

// System prompt for SHEÂ³ AI Assistant
const SYSTEM_PROMPT = `ä½ æ˜¯ SHEÂ³ï¼ˆè¯»ä½œ "She Cubed"ï¼‰å¥³æ€§å…¬ç›Šå¹³å°çš„ AI åŠ©æ‰‹ã€‚SHEÂ³ ä¸“æ³¨äºå¥³æ€§å¥åº·ä¸æ•™è‚²å…¬ç›Šã€‚ä½ çš„ä»»åŠ¡æ˜¯å¸®åŠ©ç”¨æˆ·ï¼š
1. å‘ç°å’Œæ¨èå¥³æ€§å¥åº·ã€æ•™è‚²ã€èµ‹èƒ½ç›¸å…³çš„å…¬ç›Šé¡¹ç›®
2. ååŠ©å®Œæˆæèµ æµç¨‹ï¼ˆæ”¯æŒæ‰¹é‡æèµ ç»™å¤šä¸ªé¡¹ç›®ï¼‰
3. è¿½è¸ªæèµ èµ„é‡‘çš„é“¾ä¸Šæµå‘
4. è§£ç­”å…³äºå¹³å°å’ŒåŒºå—é“¾æèµ çš„é—®é¢˜

ä½ éœ€è¦ï¼š
- æ¸©æš–ã€ä¸“ä¸šã€å¯Œæœ‰åŒç†å¿ƒ
- ç”¨ç®€æ´æ¸…æ™°çš„è¯­è¨€å›å¤
- å½“ç”¨æˆ·è¡¨è¾¾æ”¯æŒæ„æ„¿æ—¶ï¼Œå¼•å¯¼ä»–ä»¬é€‰æ‹©é¡¹ç›®
- å¼ºè°ƒå¹³å°çš„é€æ˜æ€§ï¼šAI å®¡æ ¸å‡­è¯ã€é“¾ä¸Šå­˜è¯ã€Monad åŒºå—é“¾çš„é«˜æ•ˆæ€§
- é€‚å½“ä½¿ç”¨ emojiï¼ˆğŸ’œ ğŸ’• ğŸ©º ğŸ“š âœ¨ï¼‰å¢åŠ äº²å’ŒåŠ›

å½“å‰å¯ç”¨çš„å¥³æ€§å…¬ç›Šé¡¹ç›®ï¼š
1. å†œæ‘å¥³æ€§å®«é¢ˆç™Œç­›æŸ¥è®¡åˆ’ - ä¸ºåè¿œåœ°åŒºå¥³æ€§æä¾›å…è´¹HPVæ£€æµ‹å’Œæ—©ç­›æœåŠ¡ï¼ˆå¥³æ€§å¥åº·ç±»ï¼Œç›®æ ‡$15,000ï¼Œå·²ç­¹$11,250ï¼‰
2. å±±åŒºå¥³å­©ç¼–ç¨‹å¤ä»¤è¥ - ä¸ºè´«å›°å±±åŒºå¥³å­©æä¾›STEMæ•™è‚²å’Œç¼–ç¨‹åŸ¹è®­ï¼ˆå¥³æ€§æ•™è‚²ç±»ï¼Œç›®æ ‡$20,000ï¼Œå·²ç­¹$16,000ï¼‰
3. å•äº²å¦ˆå¦ˆèŒä¸šæŠ€èƒ½åŸ¹è®­ - ä¸ºå•äº²å¦ˆå¦ˆæä¾›èŒä¸šæŠ€èƒ½åŸ¹è®­ï¼Œå¸®åŠ©ç»æµç‹¬ç«‹ï¼ˆå¥³æ€§èµ‹èƒ½ç±»ï¼Œç›®æ ‡$12,000ï¼Œå·²ç­¹$8,400ï¼‰
4. å¥³æ€§å¿ƒç†å¥åº·çƒ­çº¿ - å»ºè®¾24å°æ—¶å¥³æ€§å¿ƒç†æ´åŠ©çƒ­çº¿ï¼ˆå¿ƒç†å¥åº·ç±»ï¼Œç›®æ ‡$25,000ï¼Œå·²ç­¹$17,500ï¼‰
5. ä¹¡æ‘å¥³æ•™å¸ˆæˆé•¿è®¡åˆ’ - èµ„åŠ©åè¿œåœ°åŒºå¥³æ•™å¸ˆå‚åŠ æ•™å­¦èƒ½åŠ›æå‡åŸ¹è®­ï¼ˆå¥³æ€§æ•™è‚²ç±»ï¼Œç›®æ ‡$18,000ï¼Œå·²ç­¹$10,800ï¼‰

å¹³å°ç‰¹è‰²ï¼š
- ä½¿ç”¨ Monad åŒºå—é“¾ï¼Œäº¤æ˜“å¿«é€Ÿï¼ˆ1ç§’ç¡®è®¤ï¼‰ã€è´¹ç”¨ä½
- æ”¯æŒæ‰¹é‡æ”¯æŒï¼šç”¨æˆ·å¯ä»¥åŒæ—¶é€‰æ‹©å¤šä¸ªé¡¹ç›®ï¼Œä¸€æ¬¡æ€§å®Œæˆæèµ 
- AI è‡ªåŠ¨å®¡æ ¸å‡­è¯ï¼šé¡¹ç›®å‘èµ·äººä¸Šä¼ å‘ç¥¨/æ”¶æ®ï¼ŒAI è¯†åˆ«éªŒè¯åæ‰èƒ½ææ¬¾
- å…¨ç¨‹é€æ˜ï¼šæ‰€æœ‰äº¤æ˜“ã€å‡­è¯å®¡æ ¸ç»“æœéƒ½è®°å½•åœ¨é“¾ä¸Š

å›å¤è¦æ±‚ï¼š
- ä½¿ç”¨ä¸­æ–‡å›å¤
- æ¸©æš–æœ‰åŠ›ï¼Œæ¯æ¬¡å›å¤ä¸è¶…è¿‡ 150 å­—
- ä¸»åŠ¨å¼•å¯¼ç”¨æˆ·è¿›è¡Œä¸‹ä¸€æ­¥æ“ä½œ
- ä½“ç°å¯¹å¥³æ€§å…¬ç›Šçš„å…³æ€€`

interface ChatRequest {
  messages: { role: 'user' | 'assistant'; content: string }[]
}

export async function POST(request: NextRequest) {
  try {
    const body: ChatRequest = await request.json()
    const { messages } = body

    // Build messages array with system prompt
    const aiMessages: ChatMessage[] = [
      { role: 'system', content: SYSTEM_PROMPT },
      ...messages.map((m) => ({
        role: m.role as 'user' | 'assistant',
        content: m.content,
      })),
    ]

    // Make streaming request to AI API
    const response = await fetch(`${AI_CONFIG.baseUrl}/chat/completions`, {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${AI_CONFIG.apiKey}`,
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        model: AI_CONFIG.model,
        messages: aiMessages,
        stream: true,
        max_tokens: 500,
        temperature: 0.7,
      }),
    })

    if (!response.ok) {
      const errorText = await response.text()
      throw new Error(`AI API Error: ${response.status} - ${errorText}`)
    }

    // Create a transform stream that extracts content from SSE
    const transformStream = new TransformStream({
      async transform(chunk, controller) {
        const text = new TextDecoder().decode(chunk)
        const lines = text.split('\n').filter(line => line.trim())
        
        for (const line of lines) {
          if (line.startsWith('data: ')) {
            const data = line.slice(6)
            if (data === '[DONE]') {
              controller.terminate()
              return
            }
            
            try {
              const parsed = JSON.parse(data)
              const content = parsed.choices?.[0]?.delta?.content
              if (content) {
                // Send just the content as SSE
                controller.enqueue(new TextEncoder().encode(`data: ${JSON.stringify({ content })}\n\n`))
              }
            } catch (e) {
              // Ignore parsing errors
            }
          }
        }
      },
    })

    // Pipe the response through our transform
    const stream = response.body!.pipeThrough(transformStream)

    return new Response(stream, {
      headers: {
        'Content-Type': 'text/event-stream',
        'Cache-Control': 'no-cache',
        'Connection': 'keep-alive',
      },
    })

  } catch (error) {
    console.error('Stream chat API error:', error)
    
    // Return error as SSE
    const errorStream = new ReadableStream({
      start(controller) {
        controller.enqueue(
          new TextEncoder().encode(
            `data: ${JSON.stringify({ 
              content: 'æŠ±æ­‰ï¼Œæˆ‘é‡åˆ°äº†ä¸€ç‚¹é—®é¢˜ã€‚è¯·å†è¯•ä¸€æ¬¡ï¼Œæˆ–è€…ç›´æ¥å‘Šè¯‰æˆ‘ä½ æƒ³åšä»€ä¹ˆï¼šæ¨èé¡¹ç›®ã€è¿›è¡Œæèµ ã€æŸ¥çœ‹èµ„é‡‘æµå‘',
              error: true 
            })}\n\n`
          )
        )
        controller.close()
      },
    })

    return new Response(errorStream, {
      headers: {
        'Content-Type': 'text/event-stream',
        'Cache-Control': 'no-cache',
        'Connection': 'keep-alive',
      },
    })
  }
}
